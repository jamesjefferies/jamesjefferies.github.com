<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MongoDB | James Jefferies and ShedCode Ltd]]></title>
  <link href="http://jamesjefferies.com/categories/mongodb/atom.xml" rel="self"/>
  <link href="http://jamesjefferies.com/"/>
  <updated>2012-10-08T20:55:46+01:00</updated>
  <id>http://jamesjefferies.com/</id>
  <author>
    <name><![CDATA[James Jefferies]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[From MySQL datadump to mongo]]></title>
    <link href="http://jamesjefferies.com/2012/08/16/from-mysql-datadump-to-mongo/"/>
    <updated>2012-08-16T14:42:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/16/from-mysql-datadump-to-mongo</id>
    <content type="html"><![CDATA[<p>Let us say that you have a MySQL dump of  a database table, with a load of data which ideally, you'd like to pull into a Mongo DB as json.</p>

<p>What you could do isâ€¦</p>

<h2>Import data in to MySQL database</h2>

<p>Usual kind of thing here, assuming you have a MySQL username for a created database:</p>

<p><code>
mysql -uusername -p -Ddbname &lt; mysqldumpfile.sql
</code></p>

<h2>Export data from MySQL database in json format</h2>

<p>There is a cracking ruby gem <a href="https://github.com/seamusabshere/mysql2xxxx">mysql2xxxx</a> which will export from a mysql database to various formats, including json.</p>

<p>You can drive it via code or a number of binaries are provided. So:</p>

<p><code>
mysql2json --user=username --password=password --database=dbname --execute="select * from my_special_table" &gt; my_special_file.json
</code></p>

<h2>Importing the json straight in to your mongodb</h2>

<p>Then you can use mongoimport to pull in the json. If your export from <code>mysql2json</code> is surrounded by the square brackets, you'll need the <code>--jsonArray</code> option. Your command will need to be something like:</p>

<p><code>
mongoimport --type json --file my_special_file.json --collection mycollection --db mymongodb --jsonArray
</code></p>

<h2>Summary</h2>

<p>Simple three step transformation from MySQL dump to Mongo. You may know a better, more straightforward way of doing this, please add a comment if you do!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parse Train Describer CSV Data]]></title>
    <link href="http://jamesjefferies.com/2012/08/16/parse-train-describer-csv-data/"/>
    <updated>2012-08-16T12:35:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/16/parse-train-describer-csv-data</id>
    <content type="html"><![CDATA[<p>If you are using the Network Rail Open Data Feeds, then hopefully you've had a look at the fantastic <a href="http://wiki.openraildata.info/index.php/TD_Berth_Steps">wiki</a> started by <a href="http://twitter.com/poggs">poggs</a>.</p>

<p>In the reference data section, it provides a link to a CSV file which poggs is sharing containing Train Describer berths.</p>

<p>I wanted to parse that data using a simple ruby script and get it in to my mongo database.</p>

<p>You can use the mongoimport program to pull in the CSV by adding a header file, or you can use this little ruby script I wrote (with a <em>lot</em> of help from this <a href="http://www.dzone.com/snippets/turn-csv-headers-array-hashes">snippet</a>) which converts to JSON and inserts it in to the mongo db.</p>

<p><div><script src='https://gist.github.com/3369575.js?file='></script>
<noscript><pre><code>require 'csv'
require 'json'
require 'mongo'
=begin

Info from http://http://wiki.openraildata.info/index.php/TD_Berth_Steps

# Example header
# td_area,step_type,from_berth,to_berth,stanox,stanme,event,platform,line,trust_berth_offset,route,line,description

# Example data
AD,B,0632,0630,89321,PLUCKLY,A,1,,24,,,08-05-2012
=end

FILENAME=&quot;BerthStepsFile.csv&quot;

# You might want to change this, easily done
HEADER = ['td_area','step_type','from_berth','to_berth','stanox','stanme','event','platform','line','trust_berth_offset','route','line','description']

csv_data = CSV.read FILENAME

headers = HEADER.map {|i| i.to_s }
string_data = csv_data.map {|row| row.map {|cell| cell.to_s } }
array_of_hashes = string_data.map {|row| Hash[*headers.zip(row).flatten] }

# Assume mongo database is called rail (or it will create one if it doesn't exist)
db = Mongo::Connection.new.db(&quot;rail&quot;)

# Create/use collection called berthsteps
coll = db.collection(&quot;berthsteps&quot;)

array_of_hashes.each do |td|

  # Sanity check debug, output each td message as nice looking JSON 
  #puts JSON.pretty_generate(td)   

  # insert into collection and return with the id 
  id = coll.insert(td)

end</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Importing Network Rail Train Movement feeds into MongoDB]]></title>
    <link href="http://jamesjefferies.com/2012/08/07/importing-network-rail-train-movement-feeds-into-mongodb/"/>
    <updated>2012-08-07T14:33:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/07/importing-network-rail-train-movement-feeds-into-mongodb</id>
    <content type="html"><![CDATA[<h2>Network Rail datafeeds?</h2>

<p>Ah yes, please my previous <a href="http://jamesjefferies.com/2012/07/04/getting-started-with-network-rails-datafeeds/">blog</a> post for further info, apologies for the lack of updates on here, I've been away, sent round the loop line.</p>

<h2>Why MongoDB?</h2>

<p><a href="http://www.mongodb.org/">MongoDB</a> is a scalable, high-performance, open source, NoSQL database. I thought it would make a good fit for the train movement feeds as it's storage is oriented towards JSON-style documents. It's JSON-style because it actually uses <a href="http://bsonspec.org/">binary-encoded serialisation</a> behind the scenes.</p>

<p>There is a nice little interactive tutorial on the MongoDB home page to get you in to the swing of things.</p>

<h2>Getting Mongo installed on OS X</h2>

<p>I use <a href="http://mxcl.github.com/homebrew/">Homebrew</a> for installing packaged stuff on to my Mac, if you use it, then you can easily install it with</p>

<p><code>
brew install mongodb
</code></p>

<h2>What do you need for Ruby Mongo Magic?</h2>

<p>There is a standard Mongo driver available, which you can install using gem
<code>
gem install mongo
</code>
but it is also worth installing the C compiled extension to speed up any BSON serialisation
<code>
gem install bson_ext
</code></p>

<p>More info can be found on the <a href="http://www.mongodb.org/display/DOCS/Ruby+Language+Center">official pages</a></p>

<h2>Code example?</h2>

<p>Here you go, proper version in the <a href="https://github.com/jamesjefferies/national-rail-datafeeds-ruby-examples">github repository</a></p>

<p><div><script src='https://gist.github.com/3285558.js?file='></script>
<noscript><pre><code>require 'rubygems' 
require 'stomp'
require 'json'
require 'mongo'

begin
  # Credentials set here as environment variables
  @user = ENV[&quot;DATAFEEDS_USER&quot;]; 
  @password = ENV[&quot;DATAFEEDS_PASSWORD&quot;]
  @host = &quot;datafeeds.networkrail.co.uk&quot;
  @port = 61618

  # Example destination add yours here
  @destination = &quot;/topic/TRAIN_MVT_ALL_TOC&quot;

  puts &quot;Connecting to datafeeds as #{@user} using stomp protocol stomp://#{@host}:#{@port}\n&quot; 
  @connection = Stomp::Connection.open @user, @password, @host, @port, true 
  @connection.subscribe @destination 

  while true
    @msg = @connection.receive

    # Use JSON library to parse the messge body
    message_body = JSON.parse(@msg.body)

    db = Mongo::Connection.new.db(&quot;rail&quot;)
    coll = db.collection(&quot;td&quot;)

    message_body.each do |td| 

      # Sanity check debug, output each td message as nice looking JSON 
      # puts JSON.pretty_generate(td)   
      
      # insert into collection
      id = coll.insert(td)

    end
  end 

  @connection.disconnect
rescue 
end</code></pre></noscript></div>
</p>

<h2>Examples of querying Mongo</h2>

<p>There are lots of good examples and resources for using Mongo, but just a couple of examples related to the schema I've used in the example. You can fire up the interactive Mongo console and try the following (once you have some data!)</p>

<p>To retrieve all Departure events</p>

<p><code>
db.td.find({ "body.event_type" : "DEPARTURE" })
</code></p>

<p>To retrieve 10 (using limit) Train Movement (type 3) messages</p>

<p><code>
db.td.find({ "header.msg_type" : "0003" }).limit(10)
</code></p>
]]></content>
  </entry>
  
</feed>
