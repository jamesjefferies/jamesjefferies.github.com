<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | James Jefferies and ShedCode Ltd]]></title>
  <link href="http://jamesjefferies.com/categories/ruby/atom.xml" rel="self"/>
  <link href="http://jamesjefferies.com/"/>
  <updated>2012-11-28T15:01:59+00:00</updated>
  <id>http://jamesjefferies.com/</id>
  <author>
    <name><![CDATA[James Jefferies]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[From MySQL datadump to mongo]]></title>
    <link href="http://jamesjefferies.com/2012/08/16/from-mysql-datadump-to-mongo/"/>
    <updated>2012-08-16T14:42:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/16/from-mysql-datadump-to-mongo</id>
    <content type="html"><![CDATA[<p>Let us say that you have a MySQL dump of  a database table, with a load of data which ideally, you'd like to pull into a Mongo DB as json.</p>

<p>What you could do is…</p>

<h2>Import data in to MySQL database</h2>

<p>Usual kind of thing here, assuming you have a MySQL username for a created database:</p>

<p><code>
mysql -uusername -p -Ddbname &lt; mysqldumpfile.sql
</code></p>

<h2>Export data from MySQL database in json format</h2>

<p>There is a cracking ruby gem <a href="https://github.com/seamusabshere/mysql2xxxx">mysql2xxxx</a> which will export from a mysql database to various formats, including json.</p>

<p>You can drive it via code or a number of binaries are provided. So:</p>

<p><code>
mysql2json --user=username --password=password --database=dbname --execute="select * from my_special_table" &gt; my_special_file.json
</code></p>

<h2>Importing the json straight in to your mongodb</h2>

<p>Then you can use mongoimport to pull in the json. If your export from <code>mysql2json</code> is surrounded by the square brackets, you'll need the <code>--jsonArray</code> option. Your command will need to be something like:</p>

<p><code>
mongoimport --type json --file my_special_file.json --collection mycollection --db mymongodb --jsonArray
</code></p>

<h2>Summary</h2>

<p>Simple three step transformation from MySQL dump to Mongo. You may know a better, more straightforward way of doing this, please add a comment if you do!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parse Train Describer CSV Data]]></title>
    <link href="http://jamesjefferies.com/2012/08/16/parse-train-describer-csv-data/"/>
    <updated>2012-08-16T12:35:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/16/parse-train-describer-csv-data</id>
    <content type="html"><![CDATA[<p>If you are using the Network Rail Open Data Feeds, then hopefully you've had a look at the fantastic <a href="http://wiki.openraildata.info/index.php/TD_Berth_Steps">wiki</a> started by <a href="http://twitter.com/poggs">poggs</a>.</p>

<p>In the reference data section, it provides a link to a CSV file which poggs is sharing containing Train Describer berths.</p>

<p>I wanted to parse that data using a simple ruby script and get it in to my mongo database.</p>

<p>You can use the mongoimport program to pull in the CSV by adding a header file, or you can use this little ruby script I wrote (with a <em>lot</em> of help from this <a href="http://www.dzone.com/snippets/turn-csv-headers-array-hashes">snippet</a>) which converts to JSON and inserts it in to the mongo db.</p>

<p><div><script src='https://gist.github.com/3369575.js?file='></script>
<noscript><pre><code>require 'csv'
require 'json'
require 'mongo'
=begin

Info from http://http://wiki.openraildata.info/index.php/TD_Berth_Steps

# Example header
# td_area,step_type,from_berth,to_berth,stanox,stanme,event,platform,line,trust_berth_offset,route,line,description

# Example data
AD,B,0632,0630,89321,PLUCKLY,A,1,,24,,,08-05-2012
=end

FILENAME=&quot;BerthStepsFile.csv&quot;

# You might want to change this, easily done
HEADER = ['td_area','step_type','from_berth','to_berth','stanox','stanme','event','platform','line','trust_berth_offset','route','line','description']

csv_data = CSV.read FILENAME

headers = HEADER.map {|i| i.to_s }
string_data = csv_data.map {|row| row.map {|cell| cell.to_s } }
array_of_hashes = string_data.map {|row| Hash[*headers.zip(row).flatten] }

# Assume mongo database is called rail (or it will create one if it doesn't exist)
db = Mongo::Connection.new.db(&quot;rail&quot;)

# Create/use collection called berthsteps
coll = db.collection(&quot;berthsteps&quot;)

array_of_hashes.each do |td|

  # Sanity check debug, output each td message as nice looking JSON 
  #puts JSON.pretty_generate(td)   

  # insert into collection and return with the id 
  id = coll.insert(td)

end</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Importing Network Rail Train Movement feeds into MongoDB]]></title>
    <link href="http://jamesjefferies.com/2012/08/07/importing-network-rail-train-movement-feeds-into-mongodb/"/>
    <updated>2012-08-07T14:33:00+01:00</updated>
    <id>http://jamesjefferies.com/2012/08/07/importing-network-rail-train-movement-feeds-into-mongodb</id>
    <content type="html"><![CDATA[<h2>Network Rail datafeeds?</h2>

<p>Ah yes, please my previous <a href="http://jamesjefferies.com/2012/07/04/getting-started-with-network-rails-datafeeds/">blog</a> post for further info, apologies for the lack of updates on here, I've been away, sent round the loop line.</p>

<h2>Why MongoDB?</h2>

<p><a href="http://www.mongodb.org/">MongoDB</a> is a scalable, high-performance, open source, NoSQL database. I thought it would make a good fit for the train movement feeds as it's storage is oriented towards JSON-style documents. It's JSON-style because it actually uses <a href="http://bsonspec.org/">binary-encoded serialisation</a> behind the scenes.</p>

<p>There is a nice little interactive tutorial on the MongoDB home page to get you in to the swing of things.</p>

<h2>Getting Mongo installed on OS X</h2>

<p>I use <a href="http://mxcl.github.com/homebrew/">Homebrew</a> for installing packaged stuff on to my Mac, if you use it, then you can easily install it with</p>

<p><code>
brew install mongodb
</code></p>

<h2>What do you need for Ruby Mongo Magic?</h2>

<p>There is a standard Mongo driver available, which you can install using gem
<code>
gem install mongo
</code>
but it is also worth installing the C compiled extension to speed up any BSON serialisation
<code>
gem install bson_ext
</code></p>

<p>More info can be found on the <a href="http://www.mongodb.org/display/DOCS/Ruby+Language+Center">official pages</a></p>

<h2>Code example?</h2>

<p>Here you go, proper version in the <a href="https://github.com/jamesjefferies/national-rail-datafeeds-ruby-examples">github repository</a></p>

<p><div><script src='https://gist.github.com/3285558.js?file='></script>
<noscript><pre><code>require 'rubygems' 
require 'stomp'
require 'json'
require 'mongo'

begin
  # Credentials set here as environment variables
  @user = ENV[&quot;DATAFEEDS_USER&quot;]; 
  @password = ENV[&quot;DATAFEEDS_PASSWORD&quot;]
  @host = &quot;datafeeds.networkrail.co.uk&quot;
  @port = 61618

  # Example destination add yours here
  @destination = &quot;/topic/TRAIN_MVT_ALL_TOC&quot;

  puts &quot;Connecting to datafeeds as #{@user} using stomp protocol stomp://#{@host}:#{@port}\n&quot; 
  @connection = Stomp::Connection.open @user, @password, @host, @port, true 
  @connection.subscribe @destination 

  while true
    @msg = @connection.receive

    # Use JSON library to parse the messge body
    message_body = JSON.parse(@msg.body)

    db = Mongo::Connection.new.db(&quot;rail&quot;)
    coll = db.collection(&quot;td&quot;)

    message_body.each do |td| 

      # Sanity check debug, output each td message as nice looking JSON 
      # puts JSON.pretty_generate(td)   
      
      # insert into collection
      id = coll.insert(td)

    end
  end 

  @connection.disconnect
rescue 
end</code></pre></noscript></div>
</p>

<h2>Examples of querying Mongo</h2>

<p>There are lots of good examples and resources for using Mongo, but just a couple of examples related to the schema I've used in the example. You can fire up the interactive Mongo console and try the following (once you have some data!)</p>

<p>To retrieve all Departure events</p>

<p><code>
db.td.find({ "body.event_type" : "DEPARTURE" })
</code></p>

<p>To retrieve 10 (using limit) Train Movement (type 3) messages</p>

<p><code>
db.td.find({ "header.msg_type" : "0003" }).limit(10)
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting started with Network Rail's datafeeds]]></title>
    <link href="http://jamesjefferies.com/2012/07/04/getting-started-with-network-rails-datafeeds/"/>
    <updated>2012-07-04T23:46:41+01:00</updated>
    <id>http://jamesjefferies.com/2012/07/04/getting-started-with-network-rails-datafeeds</id>
    <content type="html"><![CDATA[<p>I've had a few railway project ideas knocking around for ages now, but have had a couple of blockers which have meant they have not progressed. Mainly lack of time and lack of data! I'm therefore clearing the decks for July and August to spend some decent time working on these ideas, which also co-incides with Network Rail giving access to a new platform providing live data feeds. You may have heard about <a href="http://www.techweekeurope.co.uk/news/network-rail-open-data-feeds-83128">the launch</a>, I believe the platform was developed in conjunction with <a href="http://rockshore.net/">Rockshore</a>, well, it's what this <a href="https://twitter.com/rockshoreltd/status/218323058493108224">tweet</a> says anyway.</p>

<h2>Where do you start?</h2>

<p>If you are interested in using the datafeeds yourself, you can read all about it on <a href="http://www.networkrail.co.uk/data-feeds/">Network Rail's site</a> which also has a link to download the developer's guide in PDF format.</p>

<p>First, you need to <a href="https://datafeeds.networkrail.co.uk/ntrod/login">create an account</a> - I believe there are limited numbers of accounts going at the moment, so the sooner you do that, the better.</p>

<p>There are two types of feeds available, pub/sub using the stomp protocol for real-ish time data &amp; downloads of huge files from Amazon S3 for timetables etc.</p>

<p>Once your account is active, you can subscribe to any of the pub/sub datafeeds you like and away you go.</p>

<h2>Receiving Messages</h2>

<p>I decided that I was going to try accessing the pub/sub datafeeds using Ruby (not my usual language) and put my experimental code on to my git hub account. Feel free to <a href="https://github.com/jamesjefferies/national-rail-datafeeds-ruby-examples">have a look and check it out</a>, I'll be using it for my initial experiments, so it should get updated beyond this basic example!</p>

<p>I've also included a sample, no error checking, very straightforward listener below. If you wish to try and run it, then you will of course need Ruby and Ruby gems installed, plus the stomp ruby gem.</p>

<p>Then, you just need to ensure your username and password are set as the relevant environment variables and away you go.</p>

<p>All being well, you should slowly receive updates from the topic you have selected. The example below uses Train positioning data for the East Midlands (TD_MC_EM_SIG_AREA) and assumes that you have subscribed to that feed using the <a href="https://datafeeds.networkrail.co.uk/ntrod/myFeeds">network rail control panel</a></p>

<p>The updates you receive from this program are not formatted at all, it's just sending the message straight to string. Of course, this is just helping you know you're set up correctly. So you would get something like:</p>

<p><code>ruby
&lt;Stomp::Message headers={"message-id"=&gt;"ID:blahblah", "destination"=&gt;"/topic/TD_MC_EM_SIG_AREA", "timestamp"=&gt;"1341436026840", "expires"=&gt;"1341436326840", "persistent"=&gt;"true", "priority"=&gt;"4"} body='[{"CA_MSG":{"to":"1234","time":"1341435963000","area_id":"WH","msg_type":"CA","from":"5678","descr":"1Z99"}}]' command='MESSAGE' &gt;
</code></p>

<p>Ultimately of course, you'd process the JSON from the body and do something with it.</p>

<h2>Example Ruby Listener</h2>

<p>``` ruby
require 'rubygems'
require 'stomp'</p>

<p>begin
  # Credentials set here as environment variables
  @user = ENV["DATAFEEDS_USER"];
  @password = ENV["DATAFEEDS_PASSWORD"]
  @host = "datafeeds.networkrail.co.uk"
  @port = 61618</p>

<p>  # Example destination add yours here
  @destination = "/topic/TD_MC_EM_SIG_AREA"</p>

<p>  puts "Connecting to datafeeds as #{@user} using stomp protocol stomp://#{@host}:#{@port}\n"
  @connection = Stomp::Connection.open @user, @password, @host, @port, true
  @connection.subscribe @destination</p>

<p>  while true</p>

<pre><code>@msg = @connection.receive
puts @msg
</code></pre>

<p>  end
  @connection.disconnect
rescue
end
```</p>
]]></content>
  </entry>
  
</feed>
